{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqoLAobFlUkrJScz1Jj+Rn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nimisha-30/Recommendation-System/blob/main/Book_Recommendation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-GMEBpnf3z5",
        "outputId": "1007a1ec-7789-49dc-dd65-6d48d6379e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: surprise in /usr/local/lib/python3.8/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.8/dist-packages (from surprise) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.7.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foH5BsGwAYM7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from random import randint\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import SVD, Reader, Dataset, accuracy\n",
        "from surprise.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Function to generate dataset with features associated to book data set.\n",
        "Input parameters: n_books:number of books,\n",
        "n_genres:number of genres,\n",
        "n_authors:number of authors,\n",
        "n_publishers:number of publishers,\n",
        "n_readers:number of readers,\n",
        "size:size of dataset. \"\"\"\n",
        "def generateData(n_books=3000, n_genres=15, n_authors=500, n_publishers=50, n_readers=30000, size=100000):\n",
        "    d=pd.DataFrame({\n",
        "        'bid': [randint(1, n_books) for _ in range(size)], # book id:string\n",
        "        'aid': [randint(1, n_authors) for _ in range(size)], # author id:string\n",
        "        'genre': [randint(1, n_genres) for _ in range(size)], # book genre:integer, value representing genre of a book, value between 0 and 16\n",
        "        'rid': [randint(1, n_readers) for _ in range(size)], # reader id:string\n",
        "        'n_pages': [randint(100, 800) for _ in range(size)], # number of pages:integer, value between 100 and 800\n",
        "        'rating': [randint(1, 10) for _ in range(size)], # book rating:integer, random value between 0 and 11\n",
        "        'pid': [randint(1, n_publishers) for _ in range(size)], # publisher id:string\n",
        "        'year': [randint(2000, 2021) for _ in range(size)], # publisher year:integer, year of publishing\n",
        "        'price': [randint(1, 200) for _ in range(size)], # book price:integer, sale price of book\n",
        "        'lang': [randint(1, 7) for _ in range(size)] # text language:integer, language of the book which is mapped to an integer\n",
        "    }).drop_duplicates()\n",
        "    return d"
      ],
      "metadata": {
        "id": "TuMzVI0cCRJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d=generateData(size=100000)\n",
        "d.to_csv('data.csv', index=False)"
      ],
      "metadata": {
        "id": "rMoZhc3YSqcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#COLLABORATIVE FILTERING SYSTEM"
      ],
      "metadata": {
        "id": "H57zA6AlVH0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Function to normalize prediction ratings.\n",
        "Input parameter: Prediction ratings - (List -> List). \"\"\"\n",
        "def normalize(pred_rating):\n",
        "    return (pred_rating-pred_rating.min())/(pred_rating.max()-pred_rating.min())"
      ],
      "metadata": {
        "id": "KfsvaChODU51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Function to calculate singular value decomposition of input matrix given n_factors.\n",
        "It will then generate and normalize the user rating predictions.\n",
        "Input parameters: scipy csr matrix corresponding to pivot table,\n",
        "pandas dataframe which is pivot table,\n",
        "number of singular values and vectors to compute\n",
        "Must be 1<=n_factors<min(mat.shape). \"\"\"\n",
        "def generate_prediction_df(mat, pt_df, n_factors):\n",
        "    if not 1<=n_factors<min(mat.shape):\n",
        "        raise ValueError(\"Must be 1<=n_factors<min(mat.shape).\")\n",
        "    # matrix factorization\n",
        "    u, s, v=svds(mat, k=n_factors)\n",
        "    s=np.diag(s)\n",
        "    # calculate prediction ratings\n",
        "    pred_rating=np.dot(np.dot(u, s), v)\n",
        "    pred_rating=normalize(pred_rating)\n",
        "    # convert to df\n",
        "    pred_df=pd.DataFrame(pred_rating, columns=pt_df.columns, index=list(pt_df.index)).transpose()\n",
        "    return pred_df"
      ],
      "metadata": {
        "id": "zq3O9teiCRMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Function to recommend items to user.\n",
        "Input parametres: pred_df:generated from 'generate_prediction_df' function,\n",
        "usr_id:user you wish to get item recommendations for,\n",
        "n_recs:number of recommendations you want for this user. \"\"\"\n",
        "def recommend_items(pred_df, usr_id, n_recs):\n",
        "    usr_pred=pred_df[usr_id].sort_values(ascending=False).reset_index().rename(columns={usr_id:'sim'})\n",
        "    rec_df=usr_pred.sort_values(by='sim', ascending=False).head(n_recs)\n",
        "    return rec_df"
      ],
      "metadata": {
        "id": "Q-iX_65lCROX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__=='__main__':\n",
        "    # constants\n",
        "    PATH='/content/data.csv'\n",
        "    # import data\n",
        "    df=pd.read_csv(PATH)\n",
        "    print(df.shape)\n",
        "    # generate a pivot table with readers on the index and books on the column and values being the ratings\n",
        "    pt_df=df.pivot_table(columns='bid', index='rid', values='rating').fillna(0)\n",
        "    # convert to csr matrix\n",
        "    mat=pt_df.values\n",
        "    mat=csr_matrix(mat)\n",
        "    pred_df=generate_prediction_df(mat, pt_df, 10)\n",
        "    #generate recommendations\n",
        "    print(recommend_items(pred_df, 5, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XqkhQJmCRSI",
        "outputId": "fd5513ca-5a00-4b40-9648-8f0e4b808715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 10)\n",
            "    bid       sim\n",
            "0  1770  0.172923\n",
            "1  1467  0.171165\n",
            "2  1269  0.170773\n",
            "3   414  0.170558\n",
            "4  1479  0.170384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CONTENT BASED SYSTEM"
      ],
      "metadata": {
        "id": "oE3hn_TUWhA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Function to normalize input data between 0 and 1.\n",
        "Input parameters: data : List - List of values to normalize. \"\"\"\n",
        "def normalize(data):\n",
        "    min_val=min(data)\n",
        "    if min_val<0:\n",
        "        data=[x+abs(min_val) for x in data]\n",
        "    max_val=max(data)\n",
        "    return [x/max_val for x in data]"
      ],
      "metadata": {
        "id": "QB5LFGfGWrw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Function is used to one hot encode specified column and add it into input dataframe.\n",
        "Input parametres: df:data frame for which results are to be appended,\n",
        "enc_col:column to OHE. \"\"\"\n",
        "def ohe(df, enc_col):\n",
        "    ohe_df=pd.get_dummies(df[enc_col])\n",
        "    ohe_df.reset_index(drop=True, inplace=True)\n",
        "    return pd.concat([df, ohe_df], axis=1)"
      ],
      "metadata": {
        "id": "ff4Ew7IAWtcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CBRecommend():\n",
        "    def __init__(self, df):\n",
        "        self.df=df\n",
        "    \"\"\" Function to calculate cosine similarity between 2 vectors. \"\"\"\n",
        "    def cosine_sim(self, v1, v2):\n",
        "        return sum(dot(v1, v2)/(norm(v1)*norm(v2)))\n",
        "    def recommend(self, bid, n_rec):\n",
        "        # calculate similarity of input book id vector wrt all other vectors\n",
        "        inputVec=self.df.loc[bid].values\n",
        "        self.df['sim']=self.df.apply(lambda x: self.cosine_sim(inputVec, x.values), axis=1)\n",
        "        # return top n user specified books\n",
        "        return self.df.nlargest(columns='sim', n=n_rec)"
      ],
      "metadata": {
        "id": "cVFkkpJoWtZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "    # constants\n",
        "    PATH='/content/data.csv'\n",
        "    # import data\n",
        "    df=pd.read_csv(PATH)\n",
        "    # normalize n_pages, ratings, price columns\n",
        "    df['n_pages_norm']=normalize(df['n_pages'].values)\n",
        "    df['rating_norm']=normalize(df['rating'].values)\n",
        "    df['price_norm']=normalize(df['price'].values)\n",
        "    # OHE on publish_year aand genre\n",
        "    df=ohe(df=df, enc_col='year')\n",
        "    df=ohe(df=df, enc_col='genre')\n",
        "    df=ohe(df=df, enc_col='lang')\n",
        "    # drop redundant columns\n",
        "    cols=['year', 'genre', 'n_pages', 'rating', 'price', 'lang']\n",
        "    df.drop(columns=cols, inplace=True)\n",
        "    df.set_index('bid', inplace=True)\n",
        "    # run on a sample as example\n",
        "    t=df.copy()\n",
        "    cbr=CBRecommend(df=t)\n",
        "    print(cbr.recommend(bid=t.index[0], n_rec=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59p8KO3MWtXL",
        "outputId": "1bb6b070-daf9-42f3-8e3a-7adb9f85006c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      aid    rid  pid  n_pages_norm  rating_norm  price_norm  2000  2001  \\\n",
            "bid                                                                        \n",
            "1813  412  27566   43       0.95250          0.4       0.080     0     0   \n",
            "1566  416  27875   43       0.99375          0.1       0.755     0     0   \n",
            "2779  405  27148   41       0.97000          0.3       0.280     0     0   \n",
            "1972  354  23660   36       0.49875          0.9       0.775     0     0   \n",
            "1995  429  28692   43       0.71000          0.5       0.780     0     0   \n",
            "\n",
            "      2002  2003  ...  14  15  1  2  3  4  5  6  7       sim  \n",
            "bid               ...                                         \n",
            "1813     0     0  ...   0   0  0  0  1  0  0  0  0  4.710501  \n",
            "1566     0     0  ...   0   0  0  0  1  0  0  0  0  4.710501  \n",
            "2779     0     0  ...   0   0  0  0  1  0  0  0  0  4.710501  \n",
            "1972     0     0  ...   0   0  0  1  0  0  0  0  0  4.710501  \n",
            "1995     0     0  ...   0   0  0  0  0  1  0  0  0  4.710501  \n",
            "\n",
            "[5 rows x 51 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HYBRID RECOMMENDATION SYSTEM"
      ],
      "metadata": {
        "id": "uccS0GEqfuW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Function flow:\n",
        "1. Use a content based model (cosine similarity) to compute the 50 most similar books.\n",
        "2. Compute the predicted rating that the user might give these 50 books using a collaborative filtering model.\n",
        "3. Return top n books with highest predicted rating."
      ],
      "metadata": {
        "id": "p9m76FCVn13f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Function represents hybrid recommendation system.\n",
        "Input parameters: rid: integer-reader id,\n",
        "bid: integer-book id,\n",
        "n_recs:integer-number of recommendations wanted,\n",
        "df:DataFrame-The cosine similarity dataframe,\n",
        "svd_model:model-SVD model. \"\"\"\n",
        "def hybrid(rid, bid, n_recs, cosine_sim, svd_model):\n",
        "    # sort similarity values in decreasing order and take top 50 results\n",
        "    sim=list(enumerate(cosine_sim[int(bid)]))\n",
        "    sim=sorted(sim, key=lambda x: x[1], reverse=True)\n",
        "    sim=sim[1:50]\n",
        "    # get book metadata\n",
        "    book_idx=[i[0] for i in sim]\n",
        "    books=df.iloc[book_idx][['bid', 'rating', 'year', 'price', 'rid']]\n",
        "    # predict using svd model\n",
        "    books['est']=books.apply(lambda x: svd_model.predict(rid, x['bid'], x['rating']).est, axis=1)\n",
        "    # sort predictions in decreasing order and return top n_recs\n",
        "    books=books.sort_values('est', ascending=False)\n",
        "    return books.head(n_recs)"
      ],
      "metadata": {
        "id": "IuYHP5AsWsat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__=='__main__':\n",
        "    # constants\n",
        "    PATH='/content/data.csv'\n",
        "    # import data\n",
        "    df=pd.read_csv(PATH)\n",
        "    # content based\n",
        "    rmat=df.pivot_table(columns='bid', index='rid', values='rating').fillna(0)\n",
        "    # compute the cosine similarity matrix\n",
        "    cosine_sim=cosine_similarity(rmat, rmat)\n",
        "    cosine_sim=pd.DataFrame(cosine_sim, index=rmat.index, columns=rmat.index)\n",
        "    # collaborative filtering\n",
        "    reader=Reader()\n",
        "    data=Dataset.load_from_df(df[['rid', 'bid', 'rating']], reader)\n",
        "    # split data into training and testing set\n",
        "    train, test=train_test_split(data, test_size=0.3, random_state=10)\n",
        "    #train\n",
        "    svd=SVD()\n",
        "    svd.fit(train)\n",
        "    # run trained model against test set\n",
        "    test_pred=svd.test(test)\n",
        "    # check accuracy\n",
        "    accuracy.rmse(test_pred, verbose=True)\n",
        "    # generate recommendations\n",
        "    r_id=df['rid'].values[0]\n",
        "    b_id=df['bid'].values[0]\n",
        "    n_recs=5\n",
        "    print(hybrid(r_id, b_id, n_recs, df, cosine_sim, svd))"
      ],
      "metadata": {
        "id": "adPLecWnf3vb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}